{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#First attempt"
      ],
      "metadata": {
        "id": "8aam604dfNLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the data"
      ],
      "metadata": {
        "id": "cwgcqFNcvk8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MTsYPJOGyVd-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# reading\n",
        "url=\"https://drive.google.com/file/d/1ljJfs1Rue1PRouBeZVl3DabqWRrfI8ZL/view?usp=share_link\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path)\n",
        "data=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder,PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error,r2_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy import sparse\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "K0KkVm9dzC9H"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=\"poisonous\")\n",
        "y = df[\"poisonous\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "a-DUSa_HzDD3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "fFq3VvP7v_N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "55uAUODawQrj",
        "outputId": "e3baa6d9-62c1-44e8-8750-b390e21aca87"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cap.shape cap.color  bruises stalk.color.above.ring  \\\n",
              "198          b         b     True                      w   \n",
              "4637         f         n     True                      p   \n",
              "3019         f         p     True                      w   \n",
              "2468         x         g    False                      w   \n",
              "6225         x         w     True                      w   \n",
              "\n",
              "     stalk.color.below.ring population    Id  \n",
              "198                       w          v  1832  \n",
              "4637                      g          y  5006  \n",
              "3019                      w          v  4040  \n",
              "2468                      w          a  5533  \n",
              "6225                      w          s  2710  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa25c04b-1602-42c8-9ee2-31cf1416744b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap.shape</th>\n",
              "      <th>cap.color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>stalk.color.above.ring</th>\n",
              "      <th>stalk.color.below.ring</th>\n",
              "      <th>population</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4637</th>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>True</td>\n",
              "      <td>p</td>\n",
              "      <td>g</td>\n",
              "      <td>y</td>\n",
              "      <td>5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3019</th>\n",
              "      <td>f</td>\n",
              "      <td>p</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>4040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2468</th>\n",
              "      <td>x</td>\n",
              "      <td>g</td>\n",
              "      <td>False</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>a</td>\n",
              "      <td>5533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6225</th>\n",
              "      <td>x</td>\n",
              "      <td>w</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>s</td>\n",
              "      <td>2710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa25c04b-1602-42c8-9ee2-31cf1416744b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa25c04b-1602-42c8-9ee2-31cf1416744b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa25c04b-1602-42c8-9ee2-31cf1416744b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXnY0HXgwHQu",
        "outputId": "56fe76ad-a20c-4b7c-9799-cb3acfec3aaf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5199 entries, 198 to 3582\n",
            "Data columns (total 7 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   cap.shape               5199 non-null   object\n",
            " 1   cap.color               5199 non-null   object\n",
            " 2   bruises                 5199 non-null   bool  \n",
            " 3   stalk.color.above.ring  5199 non-null   object\n",
            " 4   stalk.color.below.ring  5199 non-null   object\n",
            " 5   population              5199 non-null   object\n",
            " 6   Id                      5199 non-null   int64 \n",
            "dtypes: bool(1), int64(1), object(5)\n",
            "memory usage: 289.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only numeric columnn of our train set is \"Id\". Our column trandformer below will ignore it."
      ],
      "metadata": {
        "id": "l1A_1xIByWTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data"
      ],
      "metadata": {
        "id": "Ldbad4LI1Yig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_col=X_train.select_dtypes(exclude = 'number').copy().columns # Extracting the names of columns\n",
        "categoric_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"N_A\"),       # Our data set X_train has no missing value, but it might not be the case for  X_test\n",
        "    OneHotEncoder(handle_unknown=\"ignore\")\n",
        ")  \n",
        "\n",
        "numeric_pipe = make_pipeline(                                 #useful if we have meaningful nuemric columns\n",
        "    SimpleImputer(strategy=\"mean\"))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('category', categoric_pipe, cat_col)\n",
        "    #('number', numeric_pipe, num_col) # We ignore the numeric column\n",
        "])\n",
        "\n",
        "dt_pipeline = make_pipeline(preprocessor, \n",
        "                            #StandardScaler(with_mean=False) # no need to scale the onHotEncoded data\n",
        "                           )"
      ],
      "metadata": {
        "id": "FuPRShDTzDra"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded=dt_pipeline.fit_transform(X_train)\n",
        "X_train_encoded=pd.DataFrame(X_train_encoded.todense())\n",
        "\n",
        "\n",
        "X_test_encoded=dt_pipeline.transform(X_test)\n",
        "X_test_encoded=pd.DataFrame(X_test_encoded.todense())"
      ],
      "metadata": {
        "id": "hWphXaoqzDt_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network with 5 layers:\n",
        "We have a binary classification problem, and therefore set the last activation to be the sigmoid function $f(x)=\\frac{1}{1+\\exp(-x)}$."
      ],
      "metadata": {
        "id": "mll5wRTI1nOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(42,)),\n",
        "        Dense(units=30, activation='linear', name = 'layer1'),\n",
        "        Dense(20, activation='relu', name = 'layer2'),\n",
        "        Dense(5, activation='relu', name = 'layer3'),\n",
        "        Dense(3, activation='linear', name = 'layer4'),\n",
        "        Dense(1, activation='sigmoid', name = 'layer5')\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "FuwoJotezDws"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jchRcyuSzR5g",
        "outputId": "177dc907-f32e-45d7-ea1d-3cf91a0d2b75"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 30)                1290      \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 20)                620       \n",
            "                                                                 \n",
            " layer3 (Dense)              (None, 5)                 105       \n",
            "                                                                 \n",
            " layer4 (Dense)              (None, 3)                 18        \n",
            "                                                                 \n",
            " layer5 (Dense)              (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,037\n",
            "Trainable params: 2,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The binary cross entropy loss function $-y\\log(\\hat{y} )-(1-y)\\log(1-\\hat{y})$ works pretty well with binary classification problems. The optimizer Adam is faster."
      ],
      "metadata": {
        "id": "KTSVsVto33WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(                                          #compiling the model\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        ")\n",
        "\n",
        "model.fit(                                              #fitting the model\n",
        "    X_train_encoded,y_train,                            \n",
        "    epochs=100,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkldJDbQzR9V",
        "outputId": "3df3e4b2-9c0a-4768-b6ad-9648dcab6ee7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4769\n",
            "Epoch 2/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.2123\n",
            "Epoch 3/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.1417\n",
            "Epoch 4/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.1261\n",
            "Epoch 5/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.1178\n",
            "Epoch 6/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.1094\n",
            "Epoch 7/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.1047\n",
            "Epoch 8/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0998\n",
            "Epoch 9/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0984\n",
            "Epoch 10/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0971\n",
            "Epoch 11/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0948\n",
            "Epoch 12/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0955\n",
            "Epoch 13/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0950\n",
            "Epoch 14/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0935\n",
            "Epoch 15/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0917\n",
            "Epoch 16/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0922\n",
            "Epoch 17/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0926\n",
            "Epoch 18/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0921\n",
            "Epoch 19/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0929\n",
            "Epoch 20/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0913\n",
            "Epoch 21/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0923\n",
            "Epoch 22/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "Epoch 23/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "Epoch 24/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0901\n",
            "Epoch 25/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "Epoch 26/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "Epoch 27/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0900\n",
            "Epoch 28/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0906\n",
            "Epoch 29/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0900\n",
            "Epoch 30/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0894\n",
            "Epoch 31/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0894\n",
            "Epoch 32/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0891\n",
            "Epoch 33/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0901\n",
            "Epoch 34/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0899\n",
            "Epoch 35/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0912\n",
            "Epoch 36/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0887\n",
            "Epoch 37/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0887\n",
            "Epoch 38/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0895\n",
            "Epoch 39/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0884\n",
            "Epoch 40/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0886\n",
            "Epoch 41/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 42/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0888\n",
            "Epoch 43/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0884\n",
            "Epoch 44/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0892\n",
            "Epoch 45/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0879\n",
            "Epoch 46/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0891\n",
            "Epoch 47/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0885\n",
            "Epoch 48/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0891\n",
            "Epoch 49/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0895\n",
            "Epoch 50/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 51/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0873\n",
            "Epoch 52/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0884\n",
            "Epoch 53/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0886\n",
            "Epoch 54/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 55/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0889\n",
            "Epoch 56/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 57/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0877\n",
            "Epoch 58/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0878\n",
            "Epoch 59/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 60/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0876\n",
            "Epoch 61/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0871\n",
            "Epoch 62/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0883\n",
            "Epoch 63/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0878\n",
            "Epoch 64/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0875\n",
            "Epoch 65/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 66/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0880\n",
            "Epoch 67/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0869\n",
            "Epoch 68/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 69/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0877\n",
            "Epoch 70/100\n",
            "163/163 [==============================] - 0s 3ms/step - loss: 0.0878\n",
            "Epoch 71/100\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.0874\n",
            "Epoch 72/100\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.0878\n",
            "Epoch 73/100\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 0.0873\n",
            "Epoch 74/100\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.0875\n",
            "Epoch 75/100\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 0.0878\n",
            "Epoch 76/100\n",
            "163/163 [==============================] - 0s 3ms/step - loss: 0.0877\n",
            "Epoch 77/100\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.0876\n",
            "Epoch 78/100\n",
            "163/163 [==============================] - 0s 3ms/step - loss: 0.0873\n",
            "Epoch 79/100\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.0874\n",
            "Epoch 80/100\n",
            "163/163 [==============================] - 0s 3ms/step - loss: 0.0876\n",
            "Epoch 81/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 82/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0869\n",
            "Epoch 83/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0869\n",
            "Epoch 84/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 85/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0873\n",
            "Epoch 86/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 87/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0878\n",
            "Epoch 88/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0864\n",
            "Epoch 89/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0874\n",
            "Epoch 90/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0869\n",
            "Epoch 91/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0874\n",
            "Epoch 92/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0872\n",
            "Epoch 93/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0865\n",
            "Epoch 94/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0873\n",
            "Epoch 95/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0864\n",
            "Epoch 96/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 97/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0876\n",
            "Epoch 98/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 99/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0864\n",
            "Epoch 100/100\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0854\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a0d839ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictions of the model\n",
        "The model is now ready to make predictions. "
      ],
      "metadata": {
        "id": "pvA7nxxw8dPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_train_set = model.predict(X_train_encoded)    #predictions for the train set\n",
        "predictions_test_set = model.predict(X_test_encoded)      #prediction for the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prS_3my4zSBh",
        "outputId": "78046ad9-2cb4-4cc5-d939-1ba1830dc022"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that the output of our model is a vector of real numbers, each representing the probability that a given mushroom (describe by the correcponding row in the data set) is poisonous. We set our decisive treshold to be equal to $0.1$: We classify a mushroom as poisonous if, and only if our model predicts that its probability to be poisonous is strictly greater than $0.1$. "
      ],
      "metadata": {
        "id": "MnGJ2PYn97Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treshold=0.1\n",
        "yhat_train=list((pd.DataFrame(predictions_train_set).iloc[:,0]>treshold).astype(int))\n",
        "yhat_test=list((pd.DataFrame(predictions_test_set).iloc[:,0]>treshold).astype(int))"
      ],
      "metadata": {
        "id": "FbKC8mUtdgRW"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview of the predictions."
      ],
      "metadata": {
        "id": "9jQenj9Z-cB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(yhat_test[i],list(y_test)[i]) for i in range(20)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NK-npIC-p8x",
        "outputId": "003324dd-a495-48db-c360-61fe22637fcb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (1, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model performence\n",
        "\n",
        "We use the confusion matrix to evaluate the performence of our model. We compute: \n",
        "- $tn$: The number of true negatives. It corresponds to the number of eatable mushrooms that our model accurately classified.\n",
        "- $fp$: The number of false positives. It corresponds to the number of eatable mushrooms that our model missclassified.\n",
        "- $fn$: The number of false negatives. It corresponds to the number of poisonous mushrooms that our model missclassified.\n",
        "- $tp$: The number of true positives. It corresponds to the number of poisonous mushrooms that our model accurately classified."
      ],
      "metadata": {
        "id": "qcNtqq43_bxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#confusion_matrix(list(y_test),list(yhat_test))\n",
        "tn, fp, fn, tp = confusion_matrix(list(y_test),list(yhat_test)).ravel()\n",
        "tn, fp, fn, tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGsK8ha9dhDS",
        "outputId": "dc3428ef-15aa-437f-cad3-5abe6d83a408"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(604, 67, 0, 629)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#doind the task above manually\n",
        "tp_test=sum([list(yhat_test)[i]*list(y_test)[i] for i in range(len(y_test))])\n",
        "fp_test=sum([yhat_test[i]*(1-list(y_test)[i]) for i in range(len(y_test))])\n",
        "tn_test=sum([(1-yhat_test[i])*(1-list(y_test)[i]) for i in range(len(y_test))])\n",
        "fn_test=sum([(1-yhat_test[i])*list(y_test)[i] for i in range(len(y_test))])\n",
        "tn_test,fp_test,fn_test,tp_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CWNJuMvEaGB",
        "outputId": "33107a85-5a46-47b2-9d8e-c0bf2838ccfe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(602, 69, 0, 629)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the submission"
      ],
      "metadata": {
        "id": "pkYIV5Jc5LFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading\n",
        "url=\"https://drive.google.com/file/d/1rHAgVfd7vtZv3bj4Fb0MqS5PcRwOLC5I/view?usp=share_link\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df_testing = pd.read_csv(path)\n",
        "\n",
        "data_testing=df_testing.copy()\n",
        "\n",
        "X_testing_encoded=dt_pipeline.transform(data_testing)\n",
        "X_testing_encoded=pd.DataFrame(X_testing_encoded.todense())\n",
        "predictions_testing = model.predict(X_testing_encoded)\n",
        "yhat_testing=list((pd.DataFrame(predictions_testing).iloc[:,0]>treshold).astype(int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQwet_bGX4if",
        "outputId": "8a4091f0-82b7-4e9a-fbfb-ca893f51b53e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_testing[\"poisonous\"]=yhat_testing\n",
        "result=data_testing[[\"Id\",\"poisonous\"]]\n",
        "result.to_csv(\"attemp_x_Gauss.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "d0JHMxSh2ueB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Improvement?"
      ],
      "metadata": {
        "id": "HzU3h1afO0_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder,PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error,r2_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy import sparse\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "TniSjFJBO3cF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading\n",
        "url=\"https://drive.google.com/file/d/1ljJfs1Rue1PRouBeZVl3DabqWRrfI8ZL/view?usp=share_link\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path)\n",
        "data=df.copy()\n",
        "\n",
        "X = df.drop(columns=\"poisonous\")\n",
        "y = df[\"poisonous\"]\n",
        "X_train, X_, y_train, y_ = train_test_split(X, y, test_size=0.4, random_state=123)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_, y_, test_size=0.5, random_state=123)\n"
      ],
      "metadata": {
        "id": "hdsBmE3nO3fM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "scov8dtJO3iU",
        "outputId": "3a11cf28-15d8-4067-b34f-4bd59526ae0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cap.shape cap.color  bruises stalk.color.above.ring  \\\n",
              "6307         x         y     True                      w   \n",
              "2142         x         e     True                      w   \n",
              "5608         f         y     True                      w   \n",
              "3030         x         y    False                      p   \n",
              "5460         x         w    False                      w   \n",
              "\n",
              "     stalk.color.below.ring population    Id  \n",
              "6307                      w          n  7464  \n",
              "2142                      p          y   447  \n",
              "5608                      w          s  5038  \n",
              "3030                      p          v  5879  \n",
              "5460                      w          a  6916  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-558e8b04-2135-44dd-85d8-5b4e2c0f97c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap.shape</th>\n",
              "      <th>cap.color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>stalk.color.above.ring</th>\n",
              "      <th>stalk.color.below.ring</th>\n",
              "      <th>population</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6307</th>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>n</td>\n",
              "      <td>7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>x</td>\n",
              "      <td>e</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>y</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5608</th>\n",
              "      <td>f</td>\n",
              "      <td>y</td>\n",
              "      <td>True</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>s</td>\n",
              "      <td>5038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3030</th>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>False</td>\n",
              "      <td>p</td>\n",
              "      <td>p</td>\n",
              "      <td>v</td>\n",
              "      <td>5879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5460</th>\n",
              "      <td>x</td>\n",
              "      <td>w</td>\n",
              "      <td>False</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>a</td>\n",
              "      <td>6916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-558e8b04-2135-44dd-85d8-5b4e2c0f97c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-558e8b04-2135-44dd-85d8-5b4e2c0f97c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-558e8b04-2135-44dd-85d8-5b4e2c0f97c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZgNh9BvO3lQ",
        "outputId": "cc99e808-c294-4841-b55d-5b0a12903f72"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3899 entries, 6307 to 3582\n",
            "Data columns (total 7 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   cap.shape               3899 non-null   object\n",
            " 1   cap.color               3899 non-null   object\n",
            " 2   bruises                 3899 non-null   bool  \n",
            " 3   stalk.color.above.ring  3899 non-null   object\n",
            " 4   stalk.color.below.ring  3899 non-null   object\n",
            " 5   population              3899 non-null   object\n",
            " 6   Id                      3899 non-null   int64 \n",
            "dtypes: bool(1), int64(1), object(5)\n",
            "memory usage: 217.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing data\n",
        "cat_col=X_train.select_dtypes(exclude = 'number').copy().columns # Extracting the names of columns\n",
        "categoric_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"N_A\"),       # Our data set X_train has no missing value, but it might not be the case for  X_test\n",
        "    OneHotEncoder(handle_unknown=\"ignore\")\n",
        ")  \n",
        "\n",
        "numeric_pipe = make_pipeline(                                 #useful if we have meaningful nuemric columns\n",
        "    SimpleImputer(strategy=\"mean\"))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('category', categoric_pipe, cat_col)\n",
        "    #('number', numeric_pipe, num_col) # We ignore the numeric column\n",
        "])"
      ],
      "metadata": {
        "id": "g_OLbjWhO3oT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pipeline = make_pipeline(preprocessor, \n",
        "                            #PolynomialFeatures(degree=2,interaction_only=False, include_bias=True),\n",
        "                            #StandardScaler(with_mean=False) # no need to scale the onHotEncoded data\n",
        "                           )\n",
        "\n",
        "\n",
        "X_train_encoded=dt_pipeline.fit_transform(X_train)\n",
        "X_train_encoded=pd.DataFrame(X_train_encoded.todense())\n",
        "\n",
        "\n",
        "X_test_encoded=dt_pipeline.transform(X_test)\n",
        "X_test_encoded=pd.DataFrame(X_test_encoded.todense())\n",
        "\n",
        "X_val_encoded=dt_pipeline.transform(X_val)\n",
        "X_val_encoded=pd.DataFrame(X_val_encoded.todense())\n"
      ],
      "metadata": {
        "id": "ZoWK7rqnO3re"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_MI8S7zi9Jm",
        "outputId": "a142af83-f2db-4c5b-c0a2-3ed8fce8f81d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3899, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network with 5 layers:\n",
        "We have a binary classification problem, and therefore set the last activation to be the sigmoid function $f(x)=\\frac{1}{1+\\exp(-x)}$.\n"
      ],
      "metadata": {
        "id": "r4HoJRIZPj9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(X_train_encoded.shape[1],)),\n",
        "        Dense(units=45, activation='linear', name = 'layer0'),\n",
        "     \n",
        "        Dense(units=30, activation='sigmoid', name = 'layer1'),\n",
        "        Dense(20, activation='relu', name = 'layer2'),\n",
        "        Dense(5, activation='relu', name = 'layer3'),\n",
        "        Dense(3, activation='linear', name = 'layer4'),\n",
        "        Dense(1, activation='sigmoid', name = 'layer5')\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "4GdKc_OdO3uV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COWWHU1RO3xb",
        "outputId": "bc9ee4c5-8205-48f4-f690-67a076a9e429"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer0 (Dense)              (None, 45)                1890      \n",
            "                                                                 \n",
            " layer1 (Dense)              (None, 30)                1380      \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 20)                620       \n",
            "                                                                 \n",
            " layer3 (Dense)              (None, 5)                 105       \n",
            "                                                                 \n",
            " layer4 (Dense)              (None, 3)                 18        \n",
            "                                                                 \n",
            " layer5 (Dense)              (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,017\n",
            "Trainable params: 4,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The binary cross entropy loss function $-y\\log(\\hat{y} )-(1-y)\\log(1-\\hat{y})$ works pretty well with binary classification problems. The optimizer Adam is faster."
      ],
      "metadata": {
        "id": "aVevhNbOQPRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(                                          #compiling the model\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "     metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "                       tf.keras.metrics.FalseNegatives()]\n",
        ")\n",
        "\n",
        "model.fit(                                              #fitting the model\n",
        "    X_train_encoded,y_train,                            \n",
        "    epochs=100,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gXh226BPtm5",
        "outputId": "02ff6917-7337-4659-cbe1-88fe04fa700f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "122/122 [==============================] - 1s 2ms/step - loss: 0.9751 - binary_accuracy: 0.4891 - false_negatives: 0.0000e+00\n",
            "Epoch 2/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6767 - binary_accuracy: 0.5281 - false_negatives: 40.0000\n",
            "Epoch 3/100\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.7681 - false_negatives: 318.0000\n",
            "Epoch 4/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5477 - binary_accuracy: 0.8225 - false_negatives: 405.0000\n",
            "Epoch 5/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.4906 - binary_accuracy: 0.8441 - false_negatives: 366.0000\n",
            "Epoch 6/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.4437 - binary_accuracy: 0.8518 - false_negatives: 362.0000\n",
            "Epoch 7/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.4079 - binary_accuracy: 0.8595 - false_negatives: 356.0000\n",
            "Epoch 8/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.3808 - binary_accuracy: 0.8677 - false_negatives: 345.0000\n",
            "Epoch 9/100\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8777 - false_negatives: 345.0000\n",
            "Epoch 10/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8841 - false_negatives: 345.0000\n",
            "Epoch 11/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.3203 - binary_accuracy: 0.8854 - false_negatives: 345.0000\n",
            "Epoch 12/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.3025 - binary_accuracy: 0.8900 - false_negatives: 338.0000\n",
            "Epoch 13/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2852 - binary_accuracy: 0.8961 - false_negatives: 315.0000\n",
            "Epoch 14/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2685 - binary_accuracy: 0.8987 - false_negatives: 310.0000\n",
            "Epoch 15/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2528 - binary_accuracy: 0.8992 - false_negatives: 310.0000\n",
            "Epoch 16/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2377 - binary_accuracy: 0.8995 - false_negatives: 311.0000\n",
            "Epoch 17/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2221 - binary_accuracy: 0.9069 - false_negatives: 294.0000\n",
            "Epoch 18/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2057 - binary_accuracy: 0.9113 - false_negatives: 279.0000\n",
            "Epoch 19/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1917 - binary_accuracy: 0.9172 - false_negatives: 218.0000\n",
            "Epoch 20/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1802 - binary_accuracy: 0.9305 - false_negatives: 158.0000\n",
            "Epoch 21/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1701 - binary_accuracy: 0.9361 - false_negatives: 143.0000\n",
            "Epoch 22/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1612 - binary_accuracy: 0.9374 - false_negatives: 141.0000\n",
            "Epoch 23/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1537 - binary_accuracy: 0.9390 - false_negatives: 140.0000\n",
            "Epoch 24/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1476 - binary_accuracy: 0.9387 - false_negatives: 141.0000\n",
            "Epoch 25/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1419 - binary_accuracy: 0.9390 - false_negatives: 140.0000\n",
            "Epoch 26/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1373 - binary_accuracy: 0.9400 - false_negatives: 136.0000\n",
            "Epoch 27/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1333 - binary_accuracy: 0.9395 - false_negatives: 140.0000\n",
            "Epoch 28/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1299 - binary_accuracy: 0.9423 - false_negatives: 125.0000\n",
            "Epoch 29/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1271 - binary_accuracy: 0.9464 - false_negatives: 114.0000\n",
            "Epoch 30/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1251 - binary_accuracy: 0.9479 - false_negatives: 98.0000\n",
            "Epoch 31/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1224 - binary_accuracy: 0.9495 - false_negatives: 84.0000\n",
            "Epoch 32/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1202 - binary_accuracy: 0.9518 - false_negatives: 81.0000\n",
            "Epoch 33/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1183 - binary_accuracy: 0.9528 - false_negatives: 64.0000\n",
            "Epoch 34/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1168 - binary_accuracy: 0.9523 - false_negatives: 67.0000\n",
            "Epoch 35/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1155 - binary_accuracy: 0.9520 - false_negatives: 58.0000\n",
            "Epoch 36/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1143 - binary_accuracy: 0.9536 - false_negatives: 74.0000\n",
            "Epoch 37/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1132 - binary_accuracy: 0.9536 - false_negatives: 51.0000\n",
            "Epoch 38/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1119 - binary_accuracy: 0.9520 - false_negatives: 57.0000\n",
            "Epoch 39/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1108 - binary_accuracy: 0.9528 - false_negatives: 60.0000\n",
            "Epoch 40/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1101 - binary_accuracy: 0.9549 - false_negatives: 44.0000\n",
            "Epoch 41/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1091 - binary_accuracy: 0.9533 - false_negatives: 56.0000\n",
            "Epoch 42/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1083 - binary_accuracy: 0.9554 - false_negatives: 42.0000\n",
            "Epoch 43/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1083 - binary_accuracy: 0.9564 - false_negatives: 39.0000\n",
            "Epoch 44/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1078 - binary_accuracy: 0.9531 - false_negatives: 58.0000\n",
            "Epoch 45/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.9554 - false_negatives: 49.0000\n",
            "Epoch 46/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.9533 - false_negatives: 52.0000\n",
            "Epoch 47/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1057 - binary_accuracy: 0.9559 - false_negatives: 45.0000\n",
            "Epoch 48/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1053 - binary_accuracy: 0.9541 - false_negatives: 54.0000\n",
            "Epoch 49/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1049 - binary_accuracy: 0.9564 - false_negatives: 38.0000\n",
            "Epoch 50/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1040 - binary_accuracy: 0.9551 - false_negatives: 52.0000\n",
            "Epoch 51/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1041 - binary_accuracy: 0.9549 - false_negatives: 47.0000\n",
            "Epoch 52/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1040 - binary_accuracy: 0.9554 - false_negatives: 45.0000\n",
            "Epoch 53/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1038 - binary_accuracy: 0.9541 - false_negatives: 51.0000\n",
            "Epoch 54/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1033 - binary_accuracy: 0.9561 - false_negatives: 39.0000\n",
            "Epoch 55/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1034 - binary_accuracy: 0.9554 - false_negatives: 45.0000\n",
            "Epoch 56/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1028 - binary_accuracy: 0.9551 - false_negatives: 50.0000\n",
            "Epoch 57/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1023 - binary_accuracy: 0.9559 - false_negatives: 43.0000\n",
            "Epoch 58/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1026 - binary_accuracy: 0.9554 - false_negatives: 47.0000\n",
            "Epoch 59/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1020 - binary_accuracy: 0.9564 - false_negatives: 40.0000\n",
            "Epoch 60/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1017 - binary_accuracy: 0.9533 - false_negatives: 52.0000\n",
            "Epoch 61/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1012 - binary_accuracy: 0.9536 - false_negatives: 50.0000\n",
            "Epoch 62/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1017 - binary_accuracy: 0.9551 - false_negatives: 52.0000\n",
            "Epoch 63/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1012 - binary_accuracy: 0.9567 - false_negatives: 39.0000\n",
            "Epoch 64/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1010 - binary_accuracy: 0.9546 - false_negatives: 50.0000\n",
            "Epoch 65/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1010 - binary_accuracy: 0.9538 - false_negatives: 53.0000\n",
            "Epoch 66/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1003 - binary_accuracy: 0.9556 - false_negatives: 56.0000\n",
            "Epoch 67/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1003 - binary_accuracy: 0.9564 - false_negatives: 37.0000\n",
            "Epoch 68/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1007 - binary_accuracy: 0.9574 - false_negatives: 50.0000\n",
            "Epoch 69/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0999 - binary_accuracy: 0.9572 - false_negatives: 37.0000\n",
            "Epoch 70/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0997 - binary_accuracy: 0.9569 - false_negatives: 42.0000\n",
            "Epoch 71/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0997 - binary_accuracy: 0.9551 - false_negatives: 49.0000\n",
            "Epoch 72/100\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0993 - binary_accuracy: 0.9559 - false_negatives: 40.0000\n",
            "Epoch 73/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0991 - binary_accuracy: 0.9541 - false_negatives: 50.0000\n",
            "Epoch 74/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0989 - binary_accuracy: 0.9564 - false_negatives: 45.0000\n",
            "Epoch 75/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0988 - binary_accuracy: 0.9549 - false_negatives: 53.0000\n",
            "Epoch 76/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0984 - binary_accuracy: 0.9561 - false_negatives: 41.0000\n",
            "Epoch 77/100\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.0983 - binary_accuracy: 0.9556 - false_negatives: 47.0000\n",
            "Epoch 78/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0982 - binary_accuracy: 0.9556 - false_negatives: 46.0000\n",
            "Epoch 79/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0981 - binary_accuracy: 0.9564 - false_negatives: 47.0000\n",
            "Epoch 80/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0983 - binary_accuracy: 0.9567 - false_negatives: 41.0000\n",
            "Epoch 81/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0975 - binary_accuracy: 0.9564 - false_negatives: 42.0000\n",
            "Epoch 82/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0978 - binary_accuracy: 0.9556 - false_negatives: 46.0000\n",
            "Epoch 83/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0975 - binary_accuracy: 0.9559 - false_negatives: 39.0000\n",
            "Epoch 84/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0974 - binary_accuracy: 0.9564 - false_negatives: 43.0000\n",
            "Epoch 85/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0975 - binary_accuracy: 0.9538 - false_negatives: 47.0000\n",
            "Epoch 86/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0969 - binary_accuracy: 0.9546 - false_negatives: 49.0000\n",
            "Epoch 87/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0966 - binary_accuracy: 0.9564 - false_negatives: 41.0000\n",
            "Epoch 88/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0974 - binary_accuracy: 0.9531 - false_negatives: 55.0000\n",
            "Epoch 89/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0970 - binary_accuracy: 0.9551 - false_negatives: 49.0000\n",
            "Epoch 90/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0965 - binary_accuracy: 0.9559 - false_negatives: 47.0000\n",
            "Epoch 91/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0965 - binary_accuracy: 0.9551 - false_negatives: 41.0000\n",
            "Epoch 92/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0965 - binary_accuracy: 0.9551 - false_negatives: 47.0000\n",
            "Epoch 93/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0962 - binary_accuracy: 0.9559 - false_negatives: 46.0000\n",
            "Epoch 94/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0959 - binary_accuracy: 0.9546 - false_negatives: 53.0000\n",
            "Epoch 95/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0959 - binary_accuracy: 0.9567 - false_negatives: 40.0000\n",
            "Epoch 96/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0960 - binary_accuracy: 0.9559 - false_negatives: 51.0000\n",
            "Epoch 97/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0963 - binary_accuracy: 0.9554 - false_negatives: 49.0000\n",
            "Epoch 98/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0958 - binary_accuracy: 0.9551 - false_negatives: 49.0000\n",
            "Epoch 99/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0953 - binary_accuracy: 0.9569 - false_negatives: 48.0000\n",
            "Epoch 100/100\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0955 - binary_accuracy: 0.9569 - false_negatives: 36.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a1209c100>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Predictions of the model\n",
        "The model is now ready to make predictions. "
      ],
      "metadata": {
        "id": "tmvxdAZ-PyFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_train_set = model.predict(X_train_encoded)    #predictions for the train set\n",
        "predictions_val_set = model.predict(X_val_encoded)      #prediction for the val set\n",
        "predictions_test_set = model.predict(X_test_encoded)      #prediction for the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56y169u8PtqH",
        "outputId": "c74d3978-9353-4fa8-e2ca-d7c44454b450"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122/122 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that the output of our model is a vector of real numbers, each representing the probability that a given mushroom (describe by the correcponding row in the data set) is poisonous. We set our decisive treshold to be equal to $0.25$: We classify a mushroom as poisonous if, and only if our model predicts that its probability to be poisonous is strictly greater than $0.25$. "
      ],
      "metadata": {
        "id": "DYwcJ8v0P4oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treshold=0.25\n",
        "yhat_train=list((pd.DataFrame(predictions_train_set).iloc[:,0]>treshold).astype(int))\n",
        "yhat_test=list((pd.DataFrame(predictions_test_set).iloc[:,0]>treshold).astype(int))\n",
        "yhat_val=list((pd.DataFrame(predictions_val_set).iloc[:,0]>treshold).astype(int))"
      ],
      "metadata": {
        "id": "f6nMRozCPttL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Overview of the predictions."
      ],
      "metadata": {
        "id": "4ykuVmnyP-Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(yhat_test[i],list(y_test)[i]) for i in range(20)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJe-OHXzPtwE",
        "outputId": "61a13380-b88f-4d89-8592-acb47be5315f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (0, 0),\n",
              " (0, 1),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (0, 0),\n",
              " (0, 0),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 0),\n",
              " (0, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Model performence\n",
        "\n",
        "We use the confusion matrix to evaluate the performence of our model. We compute: \n",
        "- $tn$: The number of true negatives. It corresponds to the number of eatable mushrooms that our model accurately classified.\n",
        "- $fp$: The number of false positives. It corresponds to the number of eatable mushrooms that our model missclassified.\n",
        "- $fn$: The number of false negatives. It corresponds to the number of poisonous mushrooms that our model missclassified.\n",
        "- $tp$: The number of true positives. It corresponds to the number of poisonous mushrooms that our model accurately classified."
      ],
      "metadata": {
        "id": "a7gj_Q__QHqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#confusion_matrix(list(y_test),list(yhat_test))\n",
        "tn_test, fp_test, fn_test, tp_test = confusion_matrix(list(y_test),list(yhat_test)).ravel()\n",
        "tn_val, fp_val, fn_val, tp_val = confusion_matrix(list(y_val),list(yhat_val)).ravel()\n",
        "fp_test+fn_test, fp_val+fn_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgvR_mqgQBk5",
        "outputId": "e53a25e6-64f9-4c59-c5bf-5796e93076ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwp4afjCQBoE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Best treshold\n"
      ],
      "metadata": {
        "id": "CSd34tWCaPCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_treshol(y_1,y__1,y_2,y__2,y_3,y__3, ep):\n",
        "  y_1_hat=list((pd.DataFrame(y_1).iloc[:,0]>ep).astype(int))\n",
        "  y_2_hat=list((pd.DataFrame(y_2).iloc[:,0]>ep).astype(int))\n",
        "  y_3_hat=list((pd.DataFrame(y_3).iloc[:,0]>ep).astype(int))\n",
        "\n",
        "  tn_1, fp_1, fn_1, tp_1 = confusion_matrix(list(y__1),list(y_1_hat)).ravel()\n",
        "  tn_2, fp_2, fn_2, tp_2 = confusion_matrix(list(y__2),list(y_2_hat)).ravel()\n",
        "  tn_3, fp_3, fn_3, tp_3 = confusion_matrix(list(y__3),list(y_3_hat)).ravel()\n",
        "  return fp_1+fn_1,fp_2+fn_2,fp_3+fn_3\n",
        "\n"
      ],
      "metadata": {
        "id": "RA8V5zVcQBqt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_treshol(predictions_train_set,y_train,predictions_test_set,y_test,predictions_val_set,y_val, 0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3qRoN36QBtu",
        "outputId": "8056e276-de06-4bd2-8129-38d74e354210"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(495, 188, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train=[(100/len(X_train))*acc_treshol(predictions_train_set,y_train,predictions_test_set,y_test,predictions_val_set,y_val, i/100)[0] for i in range(1,100)]\n",
        "acc_test=[(100/len(X_test))*acc_treshol(predictions_train_set,y_train,predictions_test_set,y_test,predictions_val_set,y_val, i/100)[1] for i in range(1,100)]\n",
        "acc_val=[(100/len(X_val))*acc_treshol(predictions_train_set,y_train,predictions_test_set,y_test,predictions_val_set,y_val, i/100)[2] for i in range(1,100)]"
      ],
      "metadata": {
        "id": "iTKb3VPYQBw3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,60), acc_train[1:60], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=2)\n",
        "plt.plot(range(1,60), acc_test[1:60], color='red', marker='o', linestyle='dashed', linewidth=1, markersize=2)\n",
        "plt.plot(range(1,60), acc_test[1:60], color='blue', marker='o', linestyle='dashed', linewidth=1, markersize=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "WnTVkAkhQB9p",
        "outputId": "7f4ab483-59af-41e6-bc59-f46a3308e1dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3a11e92be0>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_treshol(predictions_train_set,y_train,predictions_test_set,y_test,predictions_val_set,y_val, 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttcsj5UVfMOb",
        "outputId": "91207249-dcc7-4d3b-c713-671f18518f09"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(169, 68, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not very happy with the new model.  "
      ],
      "metadata": {
        "id": "3tdaR30IzCdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treshold=0.4\n",
        "yhat_test=list((pd.DataFrame(predictions_test_set).iloc[:,0]>treshold).astype(int))\n",
        "tn_test, fp_test, fn_test, tp_test = confusion_matrix(list(y_test),list(yhat_test)).ravel()\n",
        "tn_test, fp_test, fn_test, tp_test"
      ],
      "metadata": {
        "id": "GDpn7cnwhit_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61af5761-d5e9-4221-c95d-8263fbe631f7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(637, 48, 20, 595)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next attempt we will encode the data differently and create additional features."
      ],
      "metadata": {
        "id": "qE82Ia_2393f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfPLujOqyjqM"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}